{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# To write in existing excel, need to use this\n",
    "from openpyxl import load_workbook\n",
    "# https://stackoverflow.com/questions/34744863/python-how-to-use-excelwriter-to-write-into-an-existing-worksheet\n",
    "\n",
    "\n",
    "# print(list('ab'))\n",
    "# print(list(('ab')))\n",
    "# print(list(('ab',)))\n",
    "# print(list(('ab', 'cd')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    C1  C2    C3\n",
      "R1   1   2   NaN\n",
      "R2  10  20  30.0\n",
      "    C1  C2\n",
      "R1   1  10\n",
      "R2   2  20\n",
      "      a    b      c\n",
      "R1    1    2    NaN\n",
      "R2   10   20    NaN\n",
      "R3  100  200  300.0\n"
     ]
    }
   ],
   "source": [
    "#Basic dataframes of pd\n",
    "\n",
    "#Homogeneous\n",
    "#list of dictionary :\n",
    "lst = [\n",
    "    {'C1': 1, 'C2': 2},\n",
    "    {'C1': 10, 'C2': 20, 'C3': 30}\n",
    "]\n",
    "df = pd.DataFrame(lst, index=['R1', 'R2'])\n",
    "# if  used : index=['R1', 'R2', 'R3']\n",
    "# ValueError: Shape of passed values is (3, 2), indices imply (3, 3) \n",
    "print(df)\n",
    "\n",
    "#using dictionary\n",
    "dc = {\n",
    "    'C1': [1, 2],\n",
    "    'C2': [10,20]\n",
    "}\n",
    "df = pd.DataFrame(dc, index=['R1', 'R2'])\n",
    "# if  used : index=['R1', 'R2', 'R3']\n",
    "# ValueError: Shape of passed values is (2, 2), indices imply (2, 3)\n",
    "print(df)\n",
    "\n",
    "#using list\n",
    "lst = [[1,2], [10,20], [100,200,300]]\n",
    "df = pd.DataFrame(lst, index=['R1', 'R2', 'R3'], columns=list('abc'))\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      A     B  C       D\n",
      "0  10.0  test  1  (3+2j)\n",
      "1  20.2  test  2  (3+2j)\n",
      "A       float64\n",
      "B        object\n",
      "C         int64\n",
      "D    complex128\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "#Hetrogneous\n",
    "df = pd.DataFrame({\n",
    "    'A': [10.0, 20.2],\n",
    "    'B': \"test\",\n",
    "    'C': [1, 2],\n",
    "    'D': 3+2j\n",
    "})\n",
    "# if 'A': [10.0, 20.3, 23], 'C': [1, 2]      etc...\n",
    "# ValueError: arrays must all be same length\n",
    "print(df)\n",
    "print(df.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2 entries, 0 to 1\n",
      "Data columns (total 4 columns):\n",
      "A    2 non-null float64\n",
      "B    2 non-null object\n",
      "C    2 non-null int64\n",
      "D    2 non-null complex128\n",
      "dtypes: complex128(1), float64(1), int64(1), object(1)\n",
      "memory usage: 160.0+ bytes\n",
      "Info:  None\n",
      "Index:  RangeIndex(start=0, stop=2, step=1)\n",
      "Column:  Index(['A', 'B', 'C', 'D'], dtype='object')\n",
      "Values:  [[10.0 'test' 1 (3+2j)]\n",
      " [20.2 'test' 2 (3+2j)]]\n"
     ]
    }
   ],
   "source": [
    "# extract details about dataframe \n",
    "print(\"Info: \", df.info())\n",
    "print(\"Index: \", df.index)\n",
    "print(\"Column: \", df.columns)\n",
    "print(\"Values: \", df.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      a   b\n",
      "p  0.23  f1\n",
      "q  5.36  f2\n",
      "      A   b\n",
      "p  0.23  f1\n",
      "q  5.36  f2\n",
      "      A   b   c\n",
      "p  0.23  f1  90\n",
      "q  5.36  f2   8\n",
      "           A   b   c\n",
      "p  (0.23+0j)  f1  90\n",
      "q  (5.36+0j)  f2   8 \n",
      "\n",
      "           A   b  c\n",
      "q  (5.36+0j)  f2  8\n"
     ]
    }
   ],
   "source": [
    "#Dataframe Excercise\n",
    "df = pd.DataFrame([[0.23,'f1'],[5.36,'f2']],\n",
    "                  index = list('pq'),\n",
    "                    columns = list('ab'))\n",
    "print(df)\n",
    "\n",
    "#Tasks:\n",
    "# Change the column name from ' a' to ' A'.\n",
    "# https://stackoverflow.com/questions/11346283/renaming-columns-in-pandas\n",
    "df.rename(columns={'a': 'A'}, inplace=True)\n",
    "print(df)\n",
    "\n",
    "# Add a new column ' c' filled with random values.\n",
    "df['c'] = np.random.randint(0, 100, size=2)\n",
    "print(df)\n",
    "\n",
    "# Change the datatype of column ' A' values to complex.\n",
    "df = df.astype({'A': complex})\n",
    "print(df, '\\n')\n",
    "\n",
    "# print(df[['A', 'b']])#--> dispaly selected df part\n",
    "# print(df['c'])#-->also show details about column type n name...\n",
    "# Display rows whose any of the element matches with any element of the given list:\n",
    "lst = [0.24,'f50','f2','f0'] \n",
    "# lst = [0.23,'f50','f2','f0'] \n",
    "# print(\"df1\\n\",  df[df['b'] == 'f2'] )\n",
    "# print(\"df2\\n\", df.isin(lst))\n",
    "# print(\"df3\\n\", df['b'].isin(lst))\n",
    "# print(np.any([df['A'].isin(lst), df['b'].isin(lst), df['c'].isin(lst)], axis=0))\n",
    "\n",
    "print( df[ np.any([df['A'].isin(lst), df['b'].isin(lst), df['c'].isin(lst)], axis=0) ] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    c   d\n",
      "p   5  11\n",
      "q   9 -11\n",
      "r -19   2\n",
      "s   1  -2\n",
      "t   4   6\n",
      "    c   d   m\n",
      "p   5  11  55\n",
      "q   9 -11 -99\n",
      "r -19   2 -38\n",
      "s   1  -2  -2\n",
      "t   4   6  24\n"
     ]
    }
   ],
   "source": [
    "# Dataframe operations Excercise\n",
    "clmLst = list('abcde')\n",
    "df = pd.DataFrame([[18,10,5,11,-2],\n",
    "                    [2,-2,9,-11,3],\n",
    "                    [-4,6,-19,2,1],\n",
    "                    [3,-14,1,-2,8],\n",
    "                    [-2,2,4,6,13]],\n",
    "                  index = list('pqrst'),\n",
    "                    columns = clmLst)\n",
    "\n",
    "# Filter all the two consecutive columns whose sum of individual elements is even. \n",
    "# Finally, save these columns into a new dataframe named new_df and extract the dataframe \n",
    "# in an excel file named file_df.xlsx under Sheet 1.\n",
    "# install openpyxl needed for excel creation..\n",
    "new_df = df.copy()\n",
    "\n",
    "#create sum by column axis\n",
    "new_df_sum = new_df.apply(np.sum, axis=0)\n",
    "# print(new_df_sum)\n",
    "# print([(lambda x: clmLst[x] + \"-\" + clmLst[x+1])(x) for x in range(0, len(clmLst)-1, 2)])\n",
    "data_sum_consuctive_check = [False]*len(clmLst)\n",
    "# print(data_sum_consuctive_check)\n",
    "\n",
    "# Check which consucative columns sum are even values.\n",
    "sum_test = [(lambda x: (new_df_sum[x]%2 == 0 and new_df_sum[x+1]%2 == 0) )(x) for x in range(0, len(clmLst)-1, 2)]\n",
    "\n",
    "#Update columns sum checker.\n",
    "for x in range(len(sum_test)):\n",
    "    data_sum_consuctive_check[2*x] = sum_test[x]\n",
    "    data_sum_consuctive_check[2*x+1] = sum_test[x]\n",
    "# print(data_sum_consuctive_check)\n",
    "\n",
    "# Dynamically calculating names of columsn for which 1condn match...\n",
    "columnNamesEvenSum = '*'.join( new_df.columns[data_sum_consuctive_check].values )\n",
    "\n",
    "# extract df consuctive column names for which sum is even....\n",
    "new_df = new_df[new_df.columns[data_sum_consuctive_check]]\n",
    "print(new_df)\n",
    "writer = pd.ExcelWriter('file_df.xlsx')\n",
    "new_df.to_excel(writer, sheet_name='Sheet 1')\n",
    "\n",
    "# Copy new_df dataframe into a new dataframe df_temp. Append a new column named as 'm' \n",
    "# to the df_temp dataframe which defines the multiplication of each element in one row. \n",
    "# Save this dataframe in Sheet 2 of file_df excel file.\n",
    "\n",
    "df_temp = new_df.copy()\n",
    "df_temp = df_temp.eval('m = ' + columnNamesEvenSum)\n",
    "print(df_temp)\n",
    "df_temp.to_excel(writer, sheet_name='Sheet 2')\n",
    "writer.save()\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not sure from here Educator is getting whatsapp chat. \n",
    "# I tried to use : https://regex101.com/r/iE6sA8/2 .. but didnt work for me\n",
    "\n",
    "# df = pd.read_table('whatsapp-chat-sample.txt', sep=' ', names=('date', 'time', 'msg'))\n",
    "# # print(df['date'].head(5))\n",
    "# ''' Generating a boolean sequence which results True if it contains Timestamp '''\n",
    "# bools = df.iloc[:len(df),0].str.contains(r'^\\d+\\/\\d+\\/\\d+, \\d+:\\d+:\\d+ .M:')\n",
    "# print(bools)\n",
    "# ''' Concatenating '''\n",
    "# i = len(df) - 1\n",
    "# while (i >= 0):\n",
    "#     if bools[i] == False:\n",
    "#         df.iloc[i - 1, 0] += ' ' + df.iloc[i, 0]\n",
    "#     i -= 1\n",
    "\n",
    "# ''' Dropping rows whose data is appended to source row '''\n",
    "# df = df[bools]  \n",
    "\n",
    "# ''' Reformatting index '''\n",
    "# df = df.reset_index(drop = True)    \n",
    "\n",
    "# print(df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    D   E\n",
      "A  15  12\n",
      "B  33  54\n",
      "C  10  32\n",
      "    D   E\n",
      "A  15  12\n",
      "    D   E\n",
      "A  15  12\n",
      "C  10  32\n"
     ]
    }
   ],
   "source": [
    "# Indexing and selections\n",
    "\n",
    "# https://www.quora.com/What-is-the-difference-between-columns-and-rows\n",
    "# ------- rows\n",
    "# |\n",
    "# |\n",
    "# |\n",
    "# columns\n",
    "\n",
    "# https://stackoverflow.com/questions/22149584/what-does-axis-in-pandas-mean\n",
    "# axis = 0: by column = column-wise = along the rows\n",
    "# axis = 1: by row = row-wise = along the columns\n",
    "# +------------+---------+--------+\n",
    "# |            |  A      |  B     |\n",
    "# +------------+---------+---------\n",
    "# |      0     | 0.626386| 1.52325|----axis=1----->\n",
    "# +------------+---------+--------+\n",
    "#              |         |\n",
    "#              | axis=0  |\n",
    "#              ↓         ↓\n",
    "df = pd.DataFrame([[15, 12],\n",
    "                    [33, 54],\n",
    "                    [10, 32]], \n",
    "                    index = list('ABC'),\n",
    "                    columns = list('DE'))\n",
    "# Selection by Labels\n",
    "print(df)\n",
    "# print(df['D'])\n",
    "# print(df[ ['D', 'E'] ])\n",
    "\n",
    "# print(\"\\n\")\n",
    "# print(df.loc['A'])#loc : [row, column] or [index, column]\n",
    "# print(df.loc['A']['D'])#loc : [row, column] or [index, column]\n",
    "# print(\"\\n\")\n",
    "print(df.loc[ ['A'] ])\n",
    "# print(df.loc[ ['A'] ]['D']['A'])\n",
    "# print(\"\\n\")\n",
    "print(df.loc[['A', 'C'], ['D', 'E']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    D   E\n",
      "A  15  12\n",
      "B  33  54\n",
      "C  10  32\n",
      "    D\n",
      "A  15\n",
      "B  33\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame([[15, 12],\n",
    "                    [33, 54],\n",
    "                    [10, 32]], \n",
    "                    index = list('ABC'),\n",
    "                    columns = list('DE'))\n",
    "# Selection by Position/indexing\n",
    "print(df)\n",
    "print(df.iloc[0:2, 0:1])#last index not included..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       col1  dol2\n",
      "one      15    12\n",
      "two      33    54\n",
      "three    10    32\n",
      "       col1  dol2\n",
      "one      15    12\n",
      "three    10    32\n",
      "       dol2\n",
      "one      12\n",
      "two      54\n",
      "three    32\n"
     ]
    }
   ],
   "source": [
    "# Selection Using Regular Expression\n",
    "df = pd.DataFrame([[15, 12],\n",
    "                    [33, 54],\n",
    "                    [10, 32]], \n",
    "                    index = ['one','two','three'],\n",
    "                    columns = ['col1', 'dol2'])\n",
    "print(df)\n",
    "# df.filter  --> this routine does not filter a dataframe on its contents. The filter is applied to the labels of the index.\n",
    "print(df.filter(regex = 'e$', axis=0))\n",
    "print(df.filter(regex = '^d', axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0     1\n",
      "0  15.0   NaN\n",
      "1  33.0  54.0\n",
      "2   NaN  32.0\n"
     ]
    }
   ],
   "source": [
    "# Boolean Indexing\n",
    "df = pd.DataFrame([[15, 12],\n",
    "                    [33, 54],\n",
    "                    [10, 32]])\n",
    "\n",
    "print(df[df >= 15]) # condition based selection which returns the True elements and NaN for False element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selection in WhatsApp Chat\n",
    "# Dont have log for this..\n",
    "# Some logs I found. FOr now skiping DataCleaning..\n",
    "# https://github.com/gtadiparthi/whatsapp-parser-lite/blob/master/whatsapp_chat.txt\n",
    "# https://github.com/abhisheksoni27/whatsapp-chat-analysis/blob/master/test_chat.txt\n",
    "\n",
    "# but if aurther didnot reply back to my mail for the txt files(I asked him to share the logs which he used in course)\n",
    "# will do the analysis on the above mentioned logs..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sys.version_info(major=3, minor=7, micro=1, releaselevel='final', serial=0)\n"
     ]
    }
   ],
   "source": [
    "# df.reset_index\n",
    "# df.drop_duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  IDENTIF RIVER LOCATION ERECTED   PURPOSE  LENGTH LANES CLEAR-G   T-OR-D  \\\n",
      "0      E2     A       25  CRAFTS   HIGHWAY  MEDIUM     2       N  THROUGH   \n",
      "1      E3     A       39  CRAFTS  AQUEDUCT       ?     1       N  THROUGH   \n",
      "2      E5     A       29  CRAFTS   HIGHWAY  MEDIUM     2       N  THROUGH   \n",
      "3      E6     M       23  CRAFTS   HIGHWAY       ?     2       N  THROUGH   \n",
      "4      E7     A       27  CRAFTS   HIGHWAY   SHORT     2       N  THROUGH   \n",
      "\n",
      "  MATERIAL    SPAN REL-L  TYPE  \n",
      "0     WOOD   SHORT     S  WOOD  \n",
      "1     WOOD       ?     S  WOOD  \n",
      "2     WOOD   SHORT     S  WOOD  \n",
      "3     WOOD       ?     S  WOOD  \n",
      "4     WOOD  MEDIUM     S  WOOD  \n",
      "IDENTIF     107\n",
      "RIVER       107\n",
      "LOCATION    107\n",
      "ERECTED     107\n",
      "PURPOSE     107\n",
      "LENGTH      107\n",
      "LANES       107\n",
      "CLEAR-G     107\n",
      "T-OR-D      107\n",
      "MATERIAL    107\n",
      "SPAN        107\n",
      "REL-L       107\n",
      "TYPE        107\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/22604564/create-pandas-dataframe-from-a-string\n",
    "import sys\n",
    "from io import StringIO\n",
    "    \n",
    "PittsburghData = '''E1,M,3,CRAFTS,HIGHWAY,?,2,N,THROUGH,WOOD,SHORT,S,WOOD\n",
    "E2,A,25,CRAFTS,HIGHWAY,MEDIUM,2,N,THROUGH,WOOD,SHORT,S,WOOD\n",
    "E3,A,39,CRAFTS,AQUEDUCT,?,1,N,THROUGH,WOOD,?,S,WOOD\n",
    "E5,A,29,CRAFTS,HIGHWAY,MEDIUM,2,N,THROUGH,WOOD,SHORT,S,WOOD\n",
    "E6,M,23,CRAFTS,HIGHWAY,?,2,N,THROUGH,WOOD,?,S,WOOD\n",
    "E7,A,27,CRAFTS,HIGHWAY,SHORT,2,N,THROUGH,WOOD,MEDIUM,S,WOOD\n",
    "E8,A,28,CRAFTS,AQUEDUCT,MEDIUM,1,N,THROUGH,IRON,SHORT,S,SUSPEN\n",
    "E9,M,3,CRAFTS,HIGHWAY,MEDIUM,2,N,THROUGH,IRON,SHORT,S,SUSPEN\n",
    "E10,A,39,CRAFTS,AQUEDUCT,?,1,N,DECK,WOOD,?,S,WOOD\n",
    "E11,A,29,CRAFTS,HIGHWAY,MEDIUM,2,N,THROUGH,WOOD,MEDIUM,S,WOOD\n",
    "E12,A,39,CRAFTS,RR,?,2,N,DECK,WOOD,?,S,WOOD\n",
    "E14,M,6,CRAFTS,HIGHWAY,MEDIUM,2,N,THROUGH,WOOD,MEDIUM,S,WOOD\n",
    "E13,A,33,CRAFTS,HIGHWAY,?,2,N,THROUGH,WOOD,?,S,WOOD\n",
    "E15,A,28,CRAFTS,RR,?,2,N,THROUGH,WOOD,?,S,WOOD\n",
    "E16,A,25,CRAFTS,HIGHWAY,MEDIUM,2,N,THROUGH,IRON,MEDIUM,S-F,SUSPEN\n",
    "E17,M,4,CRAFTS,RR,MEDIUM,2,N,THROUGH,IRON,MEDIUM,?,SIMPLE-T\n",
    "E18,A,28,CRAFTS,RR,MEDIUM,2,N,THROUGH,IRON,SHORT,S,SIMPLE-T\n",
    "E19,A,29,CRAFTS,HIGHWAY,MEDIUM,2,N,THROUGH,WOOD,MEDIUM,S,WOOD\n",
    "E20,A,32,EMERGING,HIGHWAY,MEDIUM,2,N,THROUGH,WOOD,MEDIUM,S,WOOD\n",
    "E21,M,16,EMERGING,RR,?,2,?,THROUGH,IRON,?,?,SIMPLE-T\n",
    "E23,M,1,EMERGING,HIGHWAY,MEDIUM,?,?,THROUGH,STEEL,LONG,F,SUSPEN\n",
    "E22,A,24,EMERGING,HIGHWAY,MEDIUM,4,G,THROUGH,WOOD,SHORT,S,WOOD\n",
    "E24,O,45,EMERGING,RR,?,2,G,?,STEEL,?,?,SIMPLE-T\n",
    "E25,M,10,EMERGING,RR,?,2,G,?,STEEL,?,?,SIMPLE-T\n",
    "E27,A,39,EMERGING,RR,?,2,G,THROUGH,STEEL,?,F,SIMPLE-T\n",
    "E26,M,12,EMERGING,RR,MEDIUM,2,G,THROUGH,STEEL,MEDIUM,S,SIMPLE-T\n",
    "E30,A,31,EMERGING,RR,?,2,G,THROUGH,STEEL,MEDIUM,F,SIMPLE-T\n",
    "E29,A,26,EMERGING,HIGHWAY,MEDIUM,2,G,THROUGH,STEEL,MEDIUM,?,SUSPEN\n",
    "E28,M,3,EMERGING,HIGHWAY,MEDIUM,2,G,THROUGH,STEEL,MEDIUM,S,ARCH\n",
    "E32,A,30,EMERGING,HIGHWAY,?,2,G,THROUGH,IRON,MEDIUM,F,SIMPLE-T\n",
    "E31,M,8,EMERGING,RR,MEDIUM,2,G,THROUGH,STEEL,MEDIUM,S,SIMPLE-T\n",
    "E34,O,41,EMERGING,RR,LONG,2,G,THROUGH,STEEL,LONG,F,SIMPLE-T\n",
    "E33,M,19,EMERGING,HIGHWAY,MEDIUM,?,G,THROUGH,IRON,MEDIUM,F,SIMPLE-T\n",
    "E36,O,45,MATURE,HIGHWAY,?,2,G,THROUGH,IRON,SHORT,F,SIMPLE-T\n",
    "E35,A,27,MATURE,HIGHWAY,MEDIUM,2,G,THROUGH,STEEL,MEDIUM,F,SIMPLE-T\n",
    "E38,M,17,MATURE,HIGHWAY,?,2,G,THROUGH,IRON,MEDIUM,F,SIMPLE-T\n",
    "E37,M,18,MATURE,RR,MEDIUM,2,G,THROUGH,STEEL,MEDIUM,S,SIMPLE-T\n",
    "E39,A,25,MATURE,HIGHWAY,?,2,G,THROUGH,STEEL,MEDIUM,F,SIMPLE-T\n",
    "E4,A,27,MATURE,AQUEDUCT,MEDIUM,1,N,THROUGH,WOOD,SHORT,S,WOOD\n",
    "E40,M,22,MATURE,HIGHWAY,?,2,G,THROUGH,STEEL,MEDIUM,F,SIMPLE-T\n",
    "E41,M,11,MATURE,HIGHWAY,?,2,G,THROUGH,IRON,MEDIUM,F,SIMPLE-T\n",
    "E42,M,9,MATURE,HIGHWAY,LONG,2,G,THROUGH,STEEL,LONG,F,SIMPLE-T\n",
    "E44,O,48,MATURE,HIGHWAY,?,2,G,THROUGH,STEEL,LONG,F,SUSPEN\n",
    "E43,M,7,MATURE,HIGHWAY,MEDIUM,2,G,THROUGH,STEEL,LONG,F,ARCH\n",
    "E46,A,37,MATURE,RR,LONG,2,G,DECK,STEEL,LONG,F,SIMPLE-T\n",
    "E45,M,14,MATURE,RR,LONG,?,G,THROUGH,STEEL,?,F,SIMPLE-T\n",
    "E47,M,15,MATURE,RR,LONG,2,G,THROUGH,STEEL,MEDIUM,S,SIMPLE-T\n",
    "E58,A,33,MATURE,HIGHWAY,MEDIUM,2,G,THROUGH,STEEL,MEDIUM,F,SIMPLE-T\n",
    "E48,A,38,MATURE,HIGHWAY,LONG,2,G,THROUGH,STEEL,MEDIUM,F,SIMPLE-T\n",
    "E94,M,13,MATURE,RR,?,2,G,THROUGH,STEEL,LONG,F,SIMPLE-T\n",
    "E49,A,34,MATURE,HIGHWAY,MEDIUM,2,G,THROUGH,STEEL,MEDIUM,F,CANTILEV\n",
    "E95,M,16,MATURE,RR,MEDIUM,2,G,THROUGH,STEEL,MEDIUM,S,SIMPLE-T\n",
    "E87,A,35,MATURE,RR,LONG,2,G,THROUGH,STEEL,MEDIUM,S,SIMPLE-T\n",
    "E51,M,6,MATURE,RR,MEDIUM,2,G,THROUGH,STEEL,MEDIUM,F,SIMPLE-T\n",
    "E50,M,21,MATURE,RR,MEDIUM,?,G,THROUGH,STEEL,LONG,F,SIMPLE-T\n",
    "E89,M,4,MATURE,RR,MEDIUM,2,G,THROUGH,STEEL,MEDIUM,S-F,SIMPLE-T\n",
    "E53,A,28,MATURE,RR,SHORT,4,G,THROUGH,STEEL,MEDIUM,S-F,SIMPLE-T\n",
    "E52,M,2,MATURE,RR,MEDIUM,?,G,THROUGH,STEEL,LONG,F,CANTILEV\n",
    "E54,Y,?,MATURE,HIGHWAY,MEDIUM,?,G,?,STEEL,MEDIUM,F,SIMPLE-T\n",
    "E56,M,23,MATURE,HIGHWAY,?,?,G,THROUGH,STEEL,MEDIUM,F,SIMPLE-T\n",
    "E55,A,36,MATURE,HIGHWAY,MEDIUM,2,G,THROUGH,STEEL,LONG,F,SIMPLE-T\n",
    "E57,O,49,MATURE,RR,MEDIUM,2,G,THROUGH,STEEL,LONG,F,CANTILEV\n",
    "E59,O,43,MATURE,HIGHWAY,MEDIUM,2,G,THROUGH,STEEL,LONG,F,CANTILEV\n",
    "E107,A,39,MATURE,RR,?,?,G,?,STEEL,?,F,NIL\n",
    "E92,M,10,MATURE,RR,LONG,?,G,THROUGH,STEEL,MEDIUM,F,SIMPLE-T\n",
    "E61,O,41,MATURE,RR,LONG,2,G,THROUGH,STEEL,LONG,F,SIMPLE-T\n",
    "E60,A,24,MATURE,HIGHWAY,MEDIUM,4,G,THROUGH,STEEL,LONG,F,SIMPLE-T\n",
    "E62,A,37,MATURE,RR,LONG,2,N,DECK,STEEL,LONG,F,CONT-T\n",
    "E63,A,31,MATURE,RR,LONG,2,G,THROUGH,STEEL,MEDIUM,F,SIMPLE-T\n",
    "E65,A,30,MATURE,WALK,?,?,G,THROUGH,STEEL,?,F,SUSPEN\n",
    "E64,A,29,MATURE,HIGHWAY,SHORT,4,G,THROUGH,STEEL,MEDIUM,F,ARCH\n",
    "E66,A,32,MATURE,HIGHWAY,LONG,4,G,THROUGH,STEEL,MEDIUM,S,ARCH\n",
    "E70,A,27,MATURE,HIGHWAY,SHORT,4,G,THROUGH,STEEL,MEDIUM,S-F,SUSPEN\n",
    "E69,A,26,MATURE,HIGHWAY,SHORT,4,G,THROUGH,STEEL,MEDIUM,S-F,SUSPEN\n",
    "E101,O,46,MATURE,HIGHWAY,MEDIUM,2,G,THROUGH,STEEL,LONG,S-F,CANTILEV\n",
    "E73,A,38,MATURE,HIGHWAY,MEDIUM,?,G,THROUGH,STEEL,MEDIUM,S,ARCH\n",
    "E72,M,5,MATURE,HIGHWAY,LONG,4,N,DECK,STEEL,MEDIUM,S-F,CANTILEV\n",
    "E67,M,1,MATURE,HIGHWAY,MEDIUM,4,G,THROUGH,STEEL,LONG,F,CANTILEV\n",
    "E75,A,30,MATURE,HIGHWAY,LONG,4,G,DECK,STEEL,MEDIUM,F,ARCH\n",
    "E74,M,20,MATURE,HIGHWAY,LONG,2,G,DECK,STEEL,MEDIUM,S-F,CANTILEV\n",
    "E71,A,25,MATURE,HIGHWAY,SHORT,4,G,THROUGH,STEEL,MEDIUM,S-F,SUSPEN\n",
    "E68,M,17,MATURE,HIGHWAY,LONG,2,G,THROUGH,STEEL,MEDIUM,S,SIMPLE-T\n",
    "E78,O,40,MATURE,HIGHWAY,MEDIUM,4,G,THROUGH,STEEL,LONG,F,ARCH\n",
    "E77,O,42,MATURE,HIGHWAY,MEDIUM,4,N,THROUGH,STEEL,LONG,F,ARCH\n",
    "E76,M,6,MATURE,HIGHWAY,MEDIUM,4,G,THROUGH,STEEL,LONG,F,SUSPEN\n",
    "E93,M,11,MATURE,HIGHWAY,MEDIUM,4,N,DECK,STEEL,LONG,S-F,CONT-T\n",
    "E79,A,34,MATURE,HIGHWAY,MEDIUM,4,G,DECK,STEEL,MEDIUM,F,CANTILEV\n",
    "E108,A,39.5,MODERN,HIGHWAY,MEDIUM,4,G,DECK,STEEL,MEDIUM,S-F,CONT-T\n",
    "E107N,A,39.7,MODERN,RR,SHORT,2,G,THROUGH,STEEL,MEDIUM,S-F,SIMPLE-T\n",
    "E105,A,38.5,MODERN,HIGHWAY,MEDIUM,2,N,DECK,STEEL,MEDIUM,S-F,CONT-T\n",
    "E103,O,48,MODERN,HIGHWAY,LONG,2,G,THROUGH,STEEL,LONG,F,CANTILEV\n",
    "E97,Y,52,MODERN,HIGHWAY,?,?,G,THROUGH,STEEL,MEDIUM,S,ARCH\n",
    "E96,Y,51,MODERN,RR,?,?,G,THROUGH,STEEL,MEDIUM,F,SIMPLE-T\n",
    "E99,M,23,MODERN,HIGHWAY,MEDIUM,2,G,THROUGH,STEEL,MEDIUM,S-F,SIMPLE-T\n",
    "E98,M,22,MODERN,HIGHWAY,SHORT,4,G,THROUGH,STEEL,MEDIUM,F,CONT-T\n",
    "E81,M,14,MODERN,HIGHWAY,LONG,4,G,DECK,STEEL,LONG,F,CONT-T\n",
    "E80,M,19,MODERN,HIGHWAY,MEDIUM,4,G,THROUGH,STEEL,LONG,F,CANTILEV\n",
    "E88,A,37,MODERN,HIGHWAY,LONG,4,N,DECK,STEEL,LONG,F,CONT-T\n",
    "E82,O,42,MODERN,HIGHWAY,SHORT,?,G,THROUGH,STEEL,?,F,SIMPLE-T\n",
    "E102,O,47,MODERN,HIGHWAY,MEDIUM,2,G,THROUGH,STEEL,LONG,F,CONT-T\n",
    "E83,M,1,MODERN,HIGHWAY,MEDIUM,6,G,THROUGH,STEEL,LONG,F,ARCH\n",
    "E86,A,33,MODERN,HIGHWAY,SHORT,4,G,DECK,STEEL,MEDIUM,S-F,CONT-T\n",
    "E85,M,9,MODERN,HIGHWAY,LONG,4,G,DECK,STEEL,LONG,F,CONT-T\n",
    "E84,A,24,MODERN,HIGHWAY,SHORT,6,G,THROUGH,STEEL,MEDIUM,F,ARCH\n",
    "E91,O,44,MODERN,HIGHWAY,LONG,6,G,THROUGH,STEEL,LONG,F,ARCH\n",
    "E90,M,7,MODERN,HIGHWAY,SHORT,6,G,THROUGH,STEEL,LONG,F,ARCH\n",
    "E100,O,43,MODERN,HIGHWAY,?,?,G,?,?,?,F,?\n",
    "E109,A,28,MODERN,HIGHWAY,?,?,G,?,?,?,F,?'''\n",
    "\n",
    "data = StringIO(PittsburghData)\n",
    "\n",
    "# Copy and save dataset to your local drive with name bridge.xlsx. Since all the data is combined into 1 column, \n",
    "# therefore, write a python code using pandas to separate this data into distinct columns.\n",
    "df = pd.read_csv(data, sep=\",\")\n",
    "# df.to_excel(\"bridge.xlsx\", sheet_name=\"Sheet 1\")\n",
    "\n",
    "# Provide header to the dataframe\n",
    "headers = ['IDENTIF','RIVER', 'LOCATION', 'ERECTED', 'PURPOSE', 'LENGTH', 'LANES', \n",
    "           'CLEAR-G', 'T-OR-D', 'MATERIAL', 'SPAN', 'REL-L', 'TYPE']\n",
    "df.columns = headers\n",
    "df.to_excel(\"bridge.xlsx\", sheet_name=\"Sheet 1\")\n",
    "\n",
    "print(df.head(5))\n",
    "\n",
    "# List names of the column(s) along with the count of missing number(?) of values\n",
    "# print(df.count(axis=0))\n",
    "# print(df == \"?\")\n",
    "print( df.count(axis=0) )\n",
    "\n",
    "# # Find the column(s) names ending with either of the following 'N', 'H', 'S'. \n",
    "# print(df.filter(regex='[NHS]$', axis=1))\n",
    "# # If the number of recorded data in these columns are less than 100, drop them.\n",
    "# # print(df.head(1))\n",
    "\n",
    "\n",
    "# Drop all the row(s) which have more than or equal to 2 missing values. What is the shape of the final DataFrame?\n",
    "# https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.dropna.html\n",
    "\n",
    "# Fill all the remaining missing values with the median of each column values.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    A   B   C\n",
      "0  15  12  -3\n",
      "1  33  54  21\n",
      "2  10  32  22\n",
      "    D      E  F\n",
      "0  10   1.00  3\n",
      "1  33 -54.00  2\n",
      "2  10   0.32  2\n",
      "    A   B   C   D      E  F\n",
      "0  15  12  -3  10   1.00  3\n",
      "1  33  54  21  33 -54.00  2\n",
      "2  10  32  22  10   0.32  2\n"
     ]
    }
   ],
   "source": [
    "# Merging\n",
    "\n",
    "data1 = pd.DataFrame([[15, 12, -3],\n",
    "                    [33, 54, 21],\n",
    "                    [10, 32, 22]],\n",
    "                    columns = list('ABC'))\n",
    "data2 = pd.DataFrame([[10, 1, 3],\n",
    "                    [33, -54, 2],\n",
    "                    [10, 0.32, 2]],\n",
    "                    columns = list('DEF'))\n",
    "\n",
    "print(data1)\n",
    "print(data2)\n",
    "# form a single dataset combining all the features particular to each observation\n",
    "print(pd.concat([data1, data2], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          A         B         C\n",
      "0  1.449251 -1.055989  0.179058\n",
      "1  0.194448  0.133042 -2.244317\n",
      "2  1.681041  0.909060  0.899500\n",
      "0  0.000000  1.000000  2.000000\n",
      "1  3.000000  4.000000  5.000000\n",
      "2  6.000000  7.000000  8.000000\n",
      "          A  A\n",
      "0  1.449251  0\n",
      "1  0.194448  3\n",
      "2  1.681041  6\n"
     ]
    }
   ],
   "source": [
    "# observation of 3 different features in two instances\n",
    "data1 = pd.DataFrame(np.random.randn(9).reshape(3,3),\n",
    "                   columns = list('ABC'))\n",
    "data2 = pd.DataFrame(np.arange(9).reshape(3,3),\n",
    "                   columns = list('ABC'))\n",
    "print(pd.concat([data1, data2], axis=0))\n",
    "\n",
    "data3 = pd.concat([data1, data2], axis=1)\n",
    "print(data3['A'] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Year1     Year2\n",
      "Country Game                     \n",
      "IND     Game1  1.624913  0.563641\n",
      "        Game2  0.290711  1.313414\n",
      "US      Game1  0.971482  1.836295\n",
      "        Game2 -0.520143 -0.637743\n",
      "Country  Game        \n",
      "IND      Game1  Year1    1.624913\n",
      "                Year2    0.563641\n",
      "         Game2  Year1    0.290711\n",
      "                Year2    1.313414\n",
      "US       Game1  Year1    0.971482\n",
      "                Year2    1.836295\n",
      "         Game2  Year1   -0.520143\n",
      "                Year2   -0.637743\n",
      "dtype: float64\n",
      "            Year1               Year2          \n",
      "Game        Game1     Game2     Game1     Game2\n",
      "Country                                        \n",
      "IND      1.624913  0.290711  0.563641  1.313414\n",
      "US       0.971482 -0.520143  1.836295 -0.637743\n"
     ]
    }
   ],
   "source": [
    "# Reshaping\n",
    "\n",
    "multi_ind = pd.MultiIndex.from_tuples([\n",
    "                                        ('IND', 'Game1'),\n",
    "                                        ('IND', 'Game2'),\n",
    "                                        ('US', 'Game1'),\n",
    "                                        ('US', 'Game2')\n",
    "                                    ], names=['Country', 'Game'])\n",
    "df = pd.DataFrame(np.random.randn(4,2), index=multi_ind, columns=['Year1', 'Year2'])\n",
    "#  we have received multiple index (Game1 and Game2) for a single index (IND/USA)\n",
    "print(df)\n",
    "# want a less complex visualization of this particular dataset\n",
    "print(df.stack())\n",
    "print(df.unstack())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       Country   Medal   Game Score\n",
      "Year1     IND    Gold  Game1   9.9\n",
      "Year2     IND  Bronze  Game2     8\n",
      "Year1     USA  Silver  Game1   9.5\n",
      "Year2     USA    Gold  Game2   8.6\n",
      "\n",
      " Game      Game1   Game2\n",
      "Country                \n",
      "IND        Gold  Bronze\n",
      "USA      Silver    Gold\n",
      "\n",
      "           Game                Score            \n",
      "Medal   Bronze   Gold Silver Bronze Gold Silver\n",
      "Country                                        \n",
      "IND      Game2  Game1    NaN      8  9.9    NaN\n",
      "USA        NaN  Game2  Game1    NaN  8.6    9.5\n",
      "\n",
      " Medal   Bronze Gold Silver\n",
      "Country                   \n",
      "IND          8  9.9    NaN\n",
      "USA        NaN  8.6    9.5\n"
     ]
    }
   ],
   "source": [
    "# Pivots\n",
    "# https://www.youtube.com/watch?v=xPPs59pn6qU\n",
    "df = pd.DataFrame([\n",
    "            ['IND', 'Gold', 'Game1', '9.9'],\n",
    "            ['IND', 'Bronze', 'Game2', '8'],\n",
    "            ['USA', 'Silver', 'Game1', '9.5'],\n",
    "            ['USA', 'Gold', 'Game2', '8.6'],\n",
    "            ], columns = ['Country', 'Medal', \n",
    "                'Game', 'Score'],\n",
    "                index = ['Year1', 'Year2','Year1', 'Year2'])\n",
    "print(\"\\n\",df)\n",
    "# Pivot tables come handy when we have to break down a large dataset (in terms of features)\n",
    "# into fewer features for quick visualization.\n",
    "print(\"\\n\",df.pivot(index='Country', columns='Game' , values='Medal' ))\n",
    "\n",
    "print(\"\\n\",df.pivot(index='Country', columns='Medal'))\n",
    "print(\"\\n\",df.pivot(index='Country', columns='Medal' , values='Score' ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Country   Medal   Game Score\n",
      "Year1     IND    Gold  Game1   9.9\n",
      "Year1     IND  Silver  Game1   9.5\n",
      "Year2     IND  Bronze  Game2     8\n",
      "Year1     USA  Bronze  Game1   9.0\n",
      "Year2     USA  Silver  Game2   8.6\n",
      "Game    Game1 Game2\n",
      "Country            \n",
      "IND       9.9     8\n",
      "USA       9.0   8.6\n"
     ]
    }
   ],
   "source": [
    "# Pivot Tables\n",
    "# https://www.youtube.com/watch?v=xPPs59pn6qU\n",
    "df = pd.DataFrame([\n",
    "            ['IND', 'Gold', 'Game1', '9.9'],\n",
    "            ['IND', 'Silver', 'Game1', '9.5'],\n",
    "            ['IND', 'Bronze', 'Game2', '8'],\n",
    "            ['USA', 'Bronze', 'Game1', '9.0'],\n",
    "            ['USA', 'Silver', 'Game2', '8.6'],\n",
    "            ], columns = ['Country', 'Medal', \n",
    "                'Game', 'Score'],\n",
    "                index = ['Year1', 'Year1', 'Year2','Year1', 'Year2'])\n",
    "print(df)\n",
    "print(df.pivot_table(index='Country', columns='Game', values='Score', aggfunc=np.max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Sales\n",
      "Category       \n",
      "Desktop    3400\n",
      "Laptop     3520\n"
     ]
    }
   ],
   "source": [
    "# Grouping\n",
    "\n",
    "df = pd.DataFrame([[\"Laptop\", 1000],\n",
    "                   [\"Laptop\", 2520],\n",
    "                   [\"Desktop\", 3000],\n",
    "                   [\"Desktop\", 400]], columns = ['Category','Sales'])\n",
    "\n",
    "print( df.groupby(['Category'], sort=True).sum() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      Median\n",
      "set_name spd_per_day        \n",
      "s1       d1             6.35\n",
      "         d2             8.95\n",
      "s2       d1             3.65\n",
      "         d2            14.40\n",
      "                      Median\n",
      "set_name spd_per_day        \n",
      "s2       d1             3.65\n",
      "s1       d1             6.35\n",
      "         d2             8.95\n",
      "s2       d2            14.40\n"
     ]
    }
   ],
   "source": [
    "# Excercise\n",
    "# Groups\n",
    "# set_name: system names\n",
    "sys = ['s1','s1','s1','s1',\n",
    "        's2','s2','s2','s2']\n",
    "# spd_per_day: Speed per day\n",
    "net_day = ['d1','d1','d2','d2',\n",
    "        'd1','d1','d2','d2']\n",
    "# speed: Network speed in MBps\n",
    "spd = [1.3, 11.4, 5.6, 12.3, \n",
    "        6.2, 1.1, 20.0, 8.8]\n",
    "df = pd.DataFrame({'set_name':sys,\n",
    "                    'spd_per_day':net_day,\n",
    "                    'speed':spd})\n",
    " \n",
    "# Construct a dataframe new_df where the given dataset is grouped based on each system (s1 and s2) \n",
    "# and speed per day (d1 and d2) with the median speed each day per system. \n",
    "# Also, provide a secondary name ' Median' for the speed attribute.\n",
    "# https://stackoverflow.com/questions/44416287/renaming-columns-after-group-by-and-sum-in-pandas-dataframe\n",
    "new_df = df.groupby(['set_name', 'spd_per_day']).median().rename(columns={'speed':'Median'})\n",
    "print(new_df)\n",
    "\n",
    "# Sort the dataframe new_df in the descending order of the median speed.\n",
    "new_df = new_df.sort_values(by=['Median'])\n",
    "print(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
